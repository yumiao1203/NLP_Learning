### 中文分词基础（一）
中文分词是中文自然语言处理领域的基础研究。分词算法包括正向匹配，反向匹配，CRF，HMM，再到现在的BiLSTM+CRF等。这里整理了中文分词的几个最基础的算法：**最大匹配算法（Maximun Matching）**MM算法有两种：一种是正向最大匹配，一种是逆向最大匹配。这几个算法都是**基于词典分词算法**。

#### 分词算法设计中的几个基本原则
- 1.颗粒度越大越好，即词的字数越多，所能表示的含义越确切，如：“公安局长”可以分为“公安 局长”、“公安局 长”、“公安局长”都算对，但是要用于语义分析，则“公安局长”的分词结果最好。
- 2.切分结果中非词典词越少越好，单字字典词数越少越好。
- 3.总体词数越少越好，在相同字数的情况下，总词数越少，说明语义单元越少，那么相对的单个语义单元的权重会越大，因此准确性会越高。


#### 算法思想
**基于词典的正向最大匹配算法（FMM）**：从左到右将待分词文本中的几个连续字符与词表匹配，如果匹配上，则切分出一个词。要做到最大匹配，所以不是第一次匹配到就可以切分的。举个例子：

待分词文本：content = {'中','华','民','族','从','此','站','了','起',来,'了'}

词表：
dict = {'中华','中华民族','从此','站起来'}

1.从content[0]开始扫描，扫描到content[1]的时候，发现'中华'已经在dict中了。但还不能切分出来，因为我们还不知道跟后面的词连起来能否组成更长的词（最大匹配）。

2.扫描到content[2]时，发现'中华民'不是dict中的词，但'中华民'是'中华民族'的前缀。

3.扫描到content[3]发现'中华民族'是dict中的词。继续扫描下去。

4.扫描到content[4]的时候，发现'中华民族从'并不是词表中的词，也不是词的前缀。因此可以切分出前面最大的词--'中华民族'。

由此可见，最大匹配出的词必须保证下一个扫描不是词表中的词或词的前缀才可以结束。

**基于词典的逆向最大匹配算法（BMM）**：

1.输入最大词长maxWordLength, 字典dict, 待分句子。

2.从待分句子的末尾开始向前截取长度为maxWordLength的子句，进行分词。

3.对一个子句的分词过程为，首先判断子句是否在字典中，若在，则保存这个子句，并从原句中删除这个子句，转到2。若不在，则判断子句长度是否为1，若为1，则将单字保存，从原句中删除单字，转到2。若不为1，则将子句中最右边的一个字删除，形成新的子句，转到3。

**由于中文的性质，反向最大匹配法优于正向最大匹配法。** 比如"结婚的和尚未结婚的"以及"为人民办公益"


**参考资料**

 [https://blog.csdn.net/SMith7412/article/details/88138197](https://blog.csdn.net/SMith7412/article/details/88138197)
 [https://blog.csdn.net/yangyan19870319/article/details/6399871](https://blog.csdn.net/yangyan19870319/article/details/6399871)
  [https://blog.csdn.net/chengzheng_hit/article/details/54752673](https://blog.csdn.net/chengzheng_hit/article/details/54752673)
 


