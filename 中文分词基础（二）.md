### 中文分词基础（二）
#### 统计语言模型
简单地说，语言模型就是用来计算一个句子的概率的模型，即P(W1,W2,...Wk)。利用语言模型，可以确定哪个词序列的可能性更大，或者给定若干个词，可以预测下一个最可能出现的词语。
如何计算一个句子的概率呢？给定句子（词语序列）S=W1,W2,……,Wk, 它的概率可以表示为：

P(S) = P(W1,W2,...,Wk)=P(W1)P(W2|W1)……P(Wk|W1,W2,……,Wk-1)

* n-gram语言模型的概念
  
  n-gram模型也称为n-1阶马尔可夫模型，即假设当前词的出现仅与前面的n-1个词相关。
  当n取1、2、3时,n-gram模型称为unigram、bigram和trigram语言模型。n-gram模型的参数就是条件概率P(Wi|Wi-n+1,……,Wi-1)。假设词表的大小为100,000，那么n-gram模型的参数数量为100,000的n次。n越大，模型越准确，也越复杂。最常用的是bigram，其次是unigram和trigram。
* n-gram模型的参数估计

  模型的参数估计也称为模型的训练，一般采用最大似然估计（Maximum Likelihood Estimation，MLE）的方法对模型的参数进行估计。以bigram为例：
  
  P(Wi|Wi-1) = C(Wi-1,Wi)/C(Wi-1)
  
  C(X)表示X在训练语料中出现的次数，训练语料的规模越大，参数估计的结果越靠谱。就算语料足够大，还是会有很多语言现象在训练集中没有出现过，导致很多参数为0。这种问题被称为**数据稀疏(Data Sparseness)**,解决数据稀疏可以通过**数据平滑(Data Smoothing)**技术来解决。
  
* n-gram模型的数据平滑

   数据平滑是对频率为0的n元对进行估计，典型的平滑算法有加法平滑、Good-Turing平滑、Katz平滑、插值平滑，等等。 
  
  
  
  
  
  
  
  
**参考资料**
[https://www.cnblogs.com/Dream-Fish/p/3963028.html](https://www.cnblogs.com/Dream-Fish/p/3963028.html)